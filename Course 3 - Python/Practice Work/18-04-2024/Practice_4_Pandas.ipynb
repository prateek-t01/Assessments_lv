{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DataAnalyticsTrainingBatch4/blob/main/Python/PracticeFiles/Practice_4_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pandas Practice Questions**"
      ],
      "metadata": {
        "id": "n9LgUPbQUD_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:1**\n",
        "A tourism company has been monitoring the weather in the Thar Desert to assess its potential for tourism.\n",
        "They collected weather data on Thursdays, Fridays, Saturdays, and Sundays over five consecutive weeks.\n",
        "However, due to occasional instrument malfunctions, weather data for some days were not recorded.\n",
        "The collected data is stored in a dictionary with days as keys and lists of average temperatures of the day (in degrees Celsius) as values.\n",
        "Days with missing data have shorter lists. Use 'NaN' for the missing values. Create a dataframe for further analysis from this dictionary and print the dataframe.\n",
        "\n",
        "weather_dict = {'Thrusday':[34, 30, 30, 29, 30],'Friday':[30, 29, 31, 29, 30],'Saturday':[29, 30, 30, 31],'Sunday':[29, 30, 31]}"
      ],
      "metadata": {
        "id": "5TE7pH81oYZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:2**\n",
        "A clothing company is planning a sale and wants to apply a discount to their existing inventory.\n",
        "They have a Pandas Series that lists the current prices (INR) of various clothing items and another series with clothes name.\n",
        "Your task is to create a DataFrame using this Series and add a new column to it. This new column 'Discounted_price' should display the prices of these items after applying a 15% discount.\n",
        "This DataFrame will assist the company in quickly understanding the new pricing structure for their upcoming sale.\n",
        "\n",
        "s1 = pd.Series(['Denim Jean', 't-shirt', 'Long Coat', 'Gym shirt', 'Sweater', 'Hoodie'])\n",
        "\n",
        "s2 = pd.Series(['3000', '1600', 1587', '2670', '3000', '2450'])"
      ],
      "metadata": {
        "id": "CiZAOpFDxaHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:3**\n",
        "You are working as a data analyst at a research company, and you've been given a dataset in the form of a nested dictionary.\n",
        "The dictionary, named data, contains measurements from three different sensors: 'A', 'C', and 'D'. Sensor 'A' is directly in the top level of the dictionary,\n",
        "while sensors 'C' and 'D' are nested within another dictionary under the key 'B'.\n",
        "The values for each sensor are stored as lists, representing a series of measurements.\n",
        "Structure the sensor data A,C, and D in effectively for further analysis.\n",
        "After structuring rename the column names 'A' as pH_sensor, 'B' as 'Ions', 'C' as 'Connectivity'\n",
        "\n",
        "Hint: Dataframe should contain 3 columns.\n",
        "\n",
        "data = {'A':[13.2, 14.2, 13.5, 13.6, 14.3], 'B':{'C':[10.2,10.4,10.6,10.7,10.8],'D':[6.5,5.4,6.7,6.6,6.5]}}"
      ],
      "metadata": {
        "id": "Ojycy7u1xcQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:4**\n",
        "A marketing analyst at a digital media company is tasked with creating a report on the performance of various advertising campaigns.\n",
        "They have campaign data for the last quarter in the form of a list of dictionaries.\n",
        "Each dictionary contains information about a single campaign, including 'CampaignID', 'StartDate', 'EndDate', 'Budget', and 'Clicks'.\n",
        "The analyst needs to compile this data into a single-index DataFrame for further analysis.\n",
        "The DataFrame should be indexed by 'CampaignID', making it easier to reference and analyze specific campaigns.\n",
        "How can the marketing analyst create a DataFrame with a single index of 'CampaignID' from the given list of dictionaries containing campaign data?\n",
        "\n",
        "Hint: There should be 5 records. Each record should contain 'CampaignID', 'StartDate', 'EndDate', 'Budget', and 'Clicks'.\n",
        "\n",
        "For ex: {'CampaignID': 'C1', 'StartDate': '2023-01-01', 'EndDate': '2023-01-15', 'Budget': 1000, 'Clicks': 150}"
      ],
      "metadata": {
        "id": "a3_Yek64xe3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:5**\n",
        "An e-commerce company is analyzing its annual sales over the past two years (2021 and 2022) to understand the performance of different products.\n",
        "They have compiled their sales data in a nested dictionary format.\n",
        "The outer keys of this dictionary represent the years (2021, 2022), while the inner keys are the names of various products they sell.\n",
        "The values associated with each product are the total sales amounts for that product in the respective year.\n",
        "Your task is to transform this nested dictionary into a Pandas DataFrame for more efficient analysis.\n",
        "The DataFrame should be structured with a MultiIndex where the first level is the year (2021, 2022) and the second level is the product name.\n",
        "Each cell in the DataFrame should display the total sales amount for that product in that year.\n",
        "This structured DataFrame will enable the company to perform more nuanced analysis and comparison of product performances across the two years.\n",
        "\n",
        "Hint: There are 3 columns Year, Product, and Sales\n",
        "\n",
        "  sales_data = {\n",
        "   2021: {\n",
        "       'ProductA': 120000,\n",
        "       'ProductB': 85000,\n",
        "       'ProductC': 94000\n",
        "   },\n",
        "   2022: {\n",
        "       'ProductA': 130000,\n",
        "       'ProductB': 90000,\n",
        "       'ProductC': 110000\n",
        "   }\n",
        "}\n"
      ],
      "metadata": {
        "id": "0RTWvmZ5xhVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:6**\n",
        "A data analyst at a retail company wants to examine sales trends during the holiday season.\n",
        "The DataFrame sales_data contains daily sales data with columns 'Date', 'TotalSales', and 'NumberOfTransactions'.\n",
        "The analyst needs to extract sales data for the month of December for the years 2022 and 2023.\n",
        "How would they use date-based indexing to retrieve this specific subset of the data?\n",
        "\n",
        "Date,\tTotalSales,\tNumberOfTransactions\n",
        "\n",
        "2022-12-01,\t8498,\t52\n",
        "\n",
        "2022-12-02,\t5977,\t90\n",
        "\n",
        "2022-12-03,\t3298,\t70\n",
        "\n",
        "2022-12-04,\t7912,\t93\n",
        "\n",
        "2022-12-05,\t7866,\t73\n",
        "\n",
        "2023-12-01,\t9000,\t80\n",
        "\n",
        "2023-12-02,\t8500, 85\n",
        "\n",
        "2023-12-03,\t7600, 75\n",
        "\n",
        "2023-12-04,\t6800, 65\n",
        "\n",
        "2023-12-05,\t7200,\t70"
      ],
      "metadata": {
        "id": "1I_HiUHlJtW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:7**\n",
        "In a company, a manager is conducting performance reviews.\n",
        "They have a DataFrame employee_data with columns 'EmployeeID', 'Name', 'Department', 'JoiningDate', and 'PerformanceScore'.\n",
        "The manager wants to review employees who joined after January 1, 2021, and are in the 'Sales' department.\n",
        "What slicing operations are needed to select the relevant rows and the columns 'Name' and 'PerformanceScore'? Use below data for creating dataframe.\n",
        "\n",
        "data = {\n",
        "    'EmployeeID': [36, 40, 41, 43, 46],\n",
        "    'Name': ['Employee_36', 'Employee_40', 'Employee_41', 'Employee_43', 'Employee_46'],\n",
        "    'Department': ['Sales', 'HR', 'Sales', 'Marketing', 'Sales'],\n",
        "    'JoiningDate': ['2022-05-01', '2020-11-15', '2021-02-20', '2019-08-10', '2021-06-30'],\n",
        "    'PerformanceScore': [4, 1, 1, 8, 5]\n",
        "}"
      ],
      "metadata": {
        "id": "WfATCaBuJwrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:8**\n",
        "A financial analyst is tasked with analyzing quarterly revenue and expenses data for a specific company stored in a DataFrame financial_data.\n",
        "The DataFrame has a MultiIndex consisting of ['Year', 'Quarter'] and columns 'Revenue' and 'Expenses'.\n",
        "The analyst needs to extract data for the second quarter of each year between 2019 and 2022, including both years, and only the columns 'Revenue' and 'Expenses'.\n",
        "How would the analyst perform this operation using appropriate method? Use the data given below.\n",
        "\n",
        "\n",
        "Year, Quarter, Revenue, Expenses\n",
        "\n",
        "2019 2         27184     16599\n",
        "\n",
        "2020 2         37790     25456\n",
        "\n",
        "2021 2         48251     33223\n",
        "\n",
        "2022 2         44124     11895\n"
      ],
      "metadata": {
        "id": "3pWGraJAJxN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:9**\n",
        "An e-commerce manager wants to compare the sales performance of two products, 'Product_A' and 'Product_B', over the last six months.\n",
        "The sales data is stored in a DataFrame sales_data with columns 'ProductID', 'Date', and 'Sales'.\n",
        "The manager needs to extract the total sales for each product for the last six months and calculate the percentage change in sales between the two products.\n",
        "What slicing and indexing operations should be used to accomplish this task?\n",
        "you have to generate random data for Date, ProductIds, and sales"
      ],
      "metadata": {
        "id": "fXyyxGQvJxnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:10**\n",
        "An e-commerce company wants to analyze customer data to identify high-value customers for targeted marketing campaigns.\n",
        "The DataFrame customer_data contains columns like 'CustomerID', 'TotalSpent', 'LastPurchaseDate', and 'Country'.\n",
        "The company defines high-value customers as those who have spent more than $1000 in total and have made a purchase in the last three months.\n",
        "How would the company use conditional indexing to filter out high-value customers? Use the data given below.\n",
        "\n",
        "customer_data = {'CustomerID': [101, 102, 103, 104, 105],\n",
        "  'TotalSpent': [800, 1200, 600, 1500, 900],\n",
        "  'LastPurchaseDate': pd.date_range('2022-01-01', periods=5),\n",
        " 'Country': ['USA', 'Canada', 'USA', 'Canada', 'USA']}\n"
      ],
      "metadata": {
        "id": "x68Rf71gJyHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:11**\n",
        "A retail store manager needs to manage inventory levels for different products based on their popularity and profitability.\n",
        "The DataFrame inventory_data contains columns like 'ProductID', 'UnitsInStock', 'Price', and 'SalesCount'.\n",
        "The manager wants to identify products that have both a high sales count (more than 100 units sold) and a high price (above $50).\n",
        "How can the manager filter the inventory data to find such products using conditional indexing? Use the data given below.\n",
        "\n",
        "inventory_data = {\n",
        "    'ProductID': ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7'],\n",
        "    'UnitsInStock': [50, 75, 20, 40, 60, 30, 80],\n",
        "    'Price': [55, 45, 60, 70, 30, 85, 65],\n",
        "    'SalesCount': [120, 95, 150, 200, 80, 130, 160]\n",
        "}"
      ],
      "metadata": {
        "id": "UnFouzOzVOeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:12**\n",
        "In a company, employees are eligible for a bonus based on their performance ratings.\n",
        "The DataFrame employee_data contains columns 'EmployeeID', 'Name', 'Department', 'PerformanceRating', and 'Salary'.\n",
        "The company has a bonus policy where employees with a performance rating of 4 or higher are eligible for a bonus.\n",
        "Additionally, employees with a performance rating of 5 and a salary above $100,000 receive an extra bonus of 10% of their salary.\n",
        "How would the company use conditional indexing to calculate bonuses for eligible employees? Use the data given below.\n",
        "\n",
        "employee_data = {\n",
        "  'EmployeeID': [101, 102, 103, 104, 105],\n",
        "  'Name': ['John', 'Emily', 'Michael', 'Sarah', 'David'],\n",
        "  'Department': ['HR', 'Finance', 'Marketing', 'IT', 'Sales'],\n",
        "  'PerformanceRating': [4, 5, 3, 4, 5],\n",
        "  'Salary': [95000, 105000, 80000, 110000, 90000]\n",
        "}"
      ],
      "metadata": {
        "id": "UPWBogTdG7TF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:13**\n",
        "A business analyst at an electronics retail company is tasked with evaluating product performance during the holiday season.\n",
        "The company has collected sales data over several years, stored in a file 'sales_data.csv', with details recorded for each transaction.\n",
        "This data includes 'Date', 'Product', 'Quantity', and 'Price' of each sold item.\n",
        "With the aim of understanding which products performed best in the critical sales period of December 2023,\n",
        "the analyst needs to calculate the total revenue generated by each product during this month.\n",
        "How can the business analyst process the 'sales_data.csv' to determine the total revenue generated by each product specifically in December 2023?\n",
        "This involves filtering the dataset for the relevant month and year, and then calculating the total revenue (Quantity multiplied by Price) for each product.\n",
        "This analysis will be vital for future inventory and marketing strategies for holiday seasons.\n",
        "\n",
        "Note: sales_data.csv dataset will be provided."
      ],
      "metadata": {
        "id": "gTTXo9DXcyig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:14**\n",
        "A health and fitness center is analyzing its members' workout logs to better understand activity patterns and plan classes and resources accordingly.\n",
        "The center has a dataset, 'workout_logs.csv', which contains records of various workout sessions.\n",
        "Each record includes 'MemberID', 'Activity', 'Duration' (in minutes), 'CaloriesBurned', and the 'Date' of the workout.\n",
        "The center wants to analyze the data by grouping it based on the 'Activity', then by 'MemberID', to understand the frequency and intensity of workouts for each member in each activity.\n",
        "How can the fitness center process the 'workout_logs.csv' to determine the total duration and total calories burned for each activity by each member?\n",
        "This detailed grouping will help in identifying which activities are most popular and which members are the most active in each type of workout.\n",
        "\n",
        "Note: workout_logs.csv dataset will be provided."
      ],
      "metadata": {
        "id": "L6aXHr5sdoo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For answering questions from **15 to 17** use **'medical_record'** data.\n",
        "\n",
        "{\n",
        "    'PatientID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'Age': [35, 45, 28, 50, 60, 42, 55, 30, 38, 65],\n",
        "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male'],\n",
        "    'VisitDate': ['2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08', '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12', '2023-01-13', '2023-01-14'],\n",
        "    'Department': ['Cardiology', 'Neurology', 'Orthopedics', 'Pediatrics', 'Gynecology', 'Dermatology', 'Ophthalmology', 'ENT (Otorhinolaryngology)', 'Urology', 'Psychiatry'],\n",
        "    'DoctorID': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
        "    'TreatmentCost': [200, 300, 250, 150, 400, 180, 350, 280, 320, 400],\n",
        "    'DurationOfVisit': [30, 45, 35, 20, 60, 25, 40, 35, 50, 55]\n",
        "}\n",
        "\n",
        "\n",
        "**Questions:15**\n",
        "The hospital's finance team wants to understand the expenditure distribution across different departments.\n",
        "They need to calculate the average and total treatment costs for each department.\n",
        "How can the finance team use Pandas to aggregate this data to provide insights into the hospital's expenditure per department?\n"
      ],
      "metadata": {
        "id": "59u0t3Pjiccv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:16**\n",
        "The hospital administration is conducting an in-depth performance review of its doctors.\n",
        "For each doctor, they want to evaluate the average treatment cost, the total duration of patient visits, and the age distribution of their patients.\n",
        "The team also needs to know the number of unique patients each doctor has attended to.\n",
        "How can the administration team use Pandas to compute these statistics for each doctor, including the average treatment cost,\n",
        "total patient handling time, average patient age, and the count of unique patients?"
      ],
      "metadata": {
        "id": "J-MevamQiesk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:17**\n",
        "The hospital's marketing and planning department is conducting a detailed analysis of patient demographics and department utilization.\n",
        "They want to analyze the average age of patients and the count of visits per gender for each department,\n",
        "as well as identify the most and least visited department by age group (e.g., under 18, 18-40, 40-60, 60+).\n",
        "Furthermore, they are interested in understanding the average duration of visits and treatment costs across these age groups in each department.\n",
        "How can the marketing team use Pandas to aggregate this comprehensive information and inform their strategic decisions?"
      ],
      "metadata": {
        "id": "i-NDqISFif-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:18**\n",
        "A retail chain has a DataFrame 'sales_data' with 'StoreID', 'Product', 'Month', and 'SalesAmount' columns, detailing sales across various stores for several months.\n",
        "The team is interested in understanding how different products perform each month to identify trends and plan stock allocations.\n",
        "Consider a method using Pandas that allows the strategy team to visualize monthly sales trends for each product across all stores.\n",
        "This should involve restructuring 'sales_data' so that each row indicates a product, each column corresponds to a month, and cells show total sales per product for each month. What approach would they take to achieve this visualization and assist in optimizing inventory for the upcoming season?Use data provided below.\n",
        "\n",
        "**Salse_data:**\n",
        "\n",
        "StoreID, Product, Month, SalesAmount\n",
        "\n",
        "1, Phones, January, 100,000\n",
        "\n",
        "1, Headphones, January, 40,000\n",
        "\n",
        "2, Smartwatches, February, 60,000\n",
        "\n",
        "2, iPad, February, 400,000\n",
        "\n",
        "3, Headphones, March, 30,000\n",
        "\n",
        "4, Smartwatches, March, 40,000\n",
        "\n",
        "5, iPad, April, 600,000\n",
        "\n",
        "6, Phones, April, 500,000\n",
        "\n"
      ],
      "metadata": {
        "id": "9cPS4Q0hiUSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:19**\n",
        "A multinational company with offices in various countries conducts an annual employee satisfaction survey.\n",
        "The survey results are compiled in a DataFrame named 'survey_data' with columns 'EmployeeID', 'Country', 'Department', 'YearsWithCompany', and 'SatisfactionScore' (ranging from 1 to 10).\n",
        "The HR team wants to focus their analysis on departments with high employee turnover.\n",
        "Their first step is to identify departments in each country with an average 'YearsWithCompany' lower than the overall average across the entire company.\n",
        "They also want to further analyze the satisfaction scores for these particular departments to plan targeted retention strategies.\n",
        "How can the HR team use Pandas to first group the data by 'Country' and 'Department' and then filter out those groups where the average 'YearsWithCompany' is less than the company-wide average?\n",
        "After identifying these departments, they need to analyze the average 'SatisfactionScore' for these groups to understand the correlation, if any, between lower tenure and employee satisfaction. Use data provided below.\n",
        "\n",
        "\n",
        "\n",
        "EmployeeID, Country, Department, YearsWithCompany, SatisfactionScore\n",
        "\n",
        "1, USA, IT, 3, 7\n",
        "\n",
        "2, USA, Marketing, 2, 6\n",
        "\n",
        "3, UK, IT, 5, 8\n",
        "\n",
        "4, UK, HR, 1, 5\n",
        "\n",
        "5, Canada, Sales, 4, 7\n"
      ],
      "metadata": {
        "id": "2FsGcB33leDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:20**\n",
        "A retail company is trying to enhance its marketing strategies by merging two complex datasets: customer demographic details and their purchase history.\n",
        "The demographic data is in a DataFrame 'customer_details' with 'CustomerID', 'Name', 'Age', 'City', and 'PreferredContactMethod'. The purchase history, stored in 'purchase_history',\n",
        "includes 'CustomerID', 'ProductID', 'PurchaseDate', 'Amount', and 'PurchaseChannel'.\n",
        "The catch is that the company wants to merge these datasets based on 'CustomerID' but also wishes to analyze if the 'PreferredContactMethod' aligns with the 'PurchaseChannel' for each customer.\n",
        "How can the company perform a merge operation on 'CustomerID' between 'customer_details' and 'purchase_history'\n",
        "and create a new column 'ContactChannelAlignment' to indicate whether the 'PreferredContactMethod' matches the 'PurchaseChannel' for each purchase record? Use data provided below.\n",
        "\n",
        "\n",
        "**customer_details:**\n",
        "\n",
        "CustomerID, Name, Age, City, PreferredContactMethod\n",
        "\n",
        "1, Alice, 30, New York, Email\n",
        "\n",
        "2, Bob, 45, Los Angeles, Phone\n",
        "\n",
        "3, Charlie, 28, Chicago, Email\n",
        "\n",
        "**purchase_history:**\n",
        "\n",
        "CustomerID, ProductID, PurchaseDate, Amount, PurchaseChannel\n",
        "\n",
        "1, 101, 2023-01-10, 150, Email\n",
        "\n",
        "1, 102, 2023-01-15, 200, Phone\n",
        "\n",
        "2, 101, 2023-01-20, 300, Phone\n",
        "\n",
        "3, 103, 2023-01-25, 100, Email\n",
        "\n"
      ],
      "metadata": {
        "id": "smxOt_aElels"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:21**\n",
        "A manufacturing company is facing a challenge in managing its inventory efficiently due to data being split across two systems.\n",
        "'Product_info' contains product details with 'ProductID', 'ProductName', 'Category', and 'DiscontinuedStatus' (indicating if a product is discontinued).\n",
        "'Inventory_data', on the other hand, includes 'ProductID', 'WarehouseID', 'StockLevel', and 'ReorderThreshold'.\n",
        "The company aims to merge these datasets for a comprehensive view but also needs to flag products that are understocked or discontinued.\n",
        "How can the company merge 'product_info' with 'inventory_data' on 'ProductID' and create two new columns - 'Understocked' to indicate if 'StockLevel' is below 'ReorderThreshold',\n",
        "and 'ActiveOrDiscontinued' to reflect the 'DiscontinuedStatus'? This advanced merging and conditional flagging will help in streamlining the inventory process,\n",
        "especially for products that are either critical or being phased out. Use data given below.\n",
        "\n",
        "\n",
        "**product_info:**\n",
        "\n",
        "ProductID, ProductName, Category, DiscontinuedStatus\n",
        "\n",
        "101, WidgetA, Electronics, False\n",
        "\n",
        "102, WidgetB, Home Goods, True\n",
        "\n",
        "103, WidgetC, Electronics, False\n",
        "\n",
        "**inventory_data:**\n",
        "\n",
        "ProductID, WarehouseID, StockLevel, ReorderThreshold\n",
        "\n",
        "101, W1, 20, 30\n",
        "\n",
        "102, W1, 15, 10\n",
        "\n",
        "103, W2, 5, 8\n"
      ],
      "metadata": {
        "id": "MaKRTtdHle9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:22**\n",
        "A multinational corporation is integrating data from its human resources (HR) and finance departments to perform a comprehensive employee analysis.\n",
        "The HR department maintains a DataFrame 'employee_details' with 'EmployeeID', 'Name', 'Department', and 'ManagerID'.\n",
        "The finance department keeps a separate DataFrame 'salary_data' with 'EmployeeID', 'Salary', and 'Bonus'.\n",
        "Additionally, the corporation wants to examine the relationship between managers and their direct reports in terms of salary structure.\n",
        "How can the corporation join the 'employee_details' data with the 'salary_data' data to combine each employee's HR and salary information?\n",
        "Furthermore, they want to identify employees who do not have corresponding salary data and list them separately for review. Use data given below.\n",
        "\n",
        "**Employee details:**\n",
        "\n",
        "EmployeeID,Name,Department,ManagerID\n",
        "\n",
        "101,Alice,HR,100\n",
        "\n",
        "102,Bob,Finance,100\n",
        "\n",
        "103,Carol,HR,101\n",
        "\n",
        "104,David,Finance,101\n",
        "\n",
        "105,Esther,HR,101\n",
        "\n",
        "**Salary data:**\n",
        "\n",
        "EmployeeID,Salary,Bonus\n",
        "\n",
        "101,60000,5000\n",
        "\n",
        "102,70000,6000\n",
        "\n",
        "103,55000,4000\n",
        "\n",
        "105,58000,4500\n"
      ],
      "metadata": {
        "id": "bw84DEoolfZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:23**\n",
        "Use above **employee_details** and **salary_data** for answering question 23.\n",
        "Once the data is integrated, how can the corporation create a new DataFrame that compares each manager's salary and bonus with the average salary and bonus of their direct reports?\n",
        "This requires a self-join on the integrated DataFrame to relate managers with their employees based on the 'ManagerID' field.\n",
        "The resulting DataFrame should have columns showing the manager's name, their salary and bonus, and the average salary and bonus of their direct reports."
      ],
      "metadata": {
        "id": "uFH0g0-I0ov-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:24**\n",
        "A climate research team is studying global warming effects in various cities.\n",
        "They've compiled a large DataFrame, 'climate_data', with columns 'City', 'Date', 'AverageTemperature', and 'Precipitation'.\n",
        "However, due to sensor malfunctions, some entries for 'AverageTemperature' and 'Precipitation' are missing.\n",
        "The team needs to handle these missing values before analysis.\n",
        "They want to fill missing 'AverageTemperature' values with the average temperature of that city from the dataset, while missing 'Precipitation' values should be set to 0,\n",
        "assuming no precipitation was recorded.\n",
        "How can the research team impute the missing 'AverageTemperature' values with the city-specific average and replace missing 'Precipitation'\n",
        "values with 0 in their 'climate_data' DataFrame? give me answer and data for this question. Use data given below.\n",
        "\n",
        "**Climate_data:**\n",
        "\n",
        "City, Date, AverageTemperature, Precipitation\n",
        "\n",
        "London, 2023-01-01, 7, 5\n",
        "\n",
        "London, 2023-01-02, 6, NaN\n",
        "\n",
        "Paris, 2023-01-01, NaN, 2\n",
        "\n",
        "Paris, 2023-01-02, 5, 4\n",
        "\n",
        "Belgium, 2023-01-01, 4, 2\n",
        "\n",
        "Belgium, 2023-01-02, NaN, 3\n",
        "\n",
        "Stockholm, 2023-01-01, NaN, 2\n",
        "\n",
        "Stockholm, 2023-01-02, 3, 4"
      ],
      "metadata": {
        "id": "8BvzC3Pc0v8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:25**\n",
        "An e-commerce company is analyzing product ratings to improve its inventory.\n",
        "The product rating data is stored in a DataFrame 'product_ratings' with columns 'ProductID', 'UserID', 'Rating' (scale of 1-5), and 'ReviewDate'.\n",
        "Some products have not been rated yet, leading to missing values in the 'Rating' column.\n",
        "The company decides to impute these missing ratings based on the average rating of all products, but only if the product has been reviewed by at least 5 users.\n",
        "Otherwise, the missing rating should be imputed as 2.5, assuming an average outlook for less-reviewed products.\n",
        "How can the e-commerce company impute the missing values in the 'Rating' column of the 'product_ratings' DataFrame based on the specified conditions:\n",
        "using the average rating for products with 5 or more reviews, and a default value of 2.5 for others? Use data given below.\n",
        "\n",
        "\n",
        "ProductID, UserID, Rating, ReviewDate\n",
        "\n",
        "1001, User1, 4, 2023-01-01\n",
        "\n",
        "1001, User2, 5, 2023-01-02\n",
        "\n",
        "1002, User3, NaN, 2023-01-03\n",
        "\n",
        "1002, User4, 3, 2023-01-04\n",
        "\n",
        "1003, User5, NaN, 2023-01-05\n",
        "\n",
        "1003, User6, NaN, 2023-01-06\n"
      ],
      "metadata": {
        "id": "JIteGwNS1WIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:26**\n",
        "Use 'energy_consumption.csv' to answer from question 26 to 28\n",
        "Suppose we have a dataset named 'energy_consumption.csv' collected from a smart grid system.\n",
        "This dataset includes columns like 'Timestamp', 'HouseID', 'EnergyUsage_kWh', 'OutdoorTemp', 'UserSatisfaction', and 'ApplianceType'.\n",
        "The dataset spans over a year, with varying energy usage patterns, temperatures, and user feedback.\n",
        "The data science team at the energy company is facing a challenge due to significant variations in the scale of energy usage values ('EnergyUsage_kWh'),\n",
        "what techniques could they use to scale and normalize these values, considering the differences in house sizes and number of appliances,\n",
        "in order to enable a fair and standardized comparison of energy usage patterns across different households?"
      ],
      "metadata": {
        "id": "wbpUGy-T1X4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:27**\n",
        "As part of the effort to optimize energy distribution, the company wants to identify abnormal energy consumption patterns that could indicate issues like equipment\n",
        "malfunctions or energy leaks. How can the team use statistical methods to detect outliers in the 'EnergyUsage_kWh' column of their dataset?"
      ],
      "metadata": {
        "id": "nBKBJBP01YYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:28**\n",
        "For a marketing campaign, the company wants to analyze the types of appliances used in different households ('ApplianceType') and\n",
        "correlate this with user satisfaction ('UserSatisfaction'). However, 'ApplianceType' is a categorical variable.\n",
        "How can the team encode this variable for quantitative analysis and compute descriptive statistics to understand the relationship between appliance types and user satisfaction?"
      ],
      "metadata": {
        "id": "BjAIkQyh1Yp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:29**\n",
        "Use **campaign_data.csv** file.\n",
        "A digital marketing agency is tasked with optimizing an online advertising campaign. They have access to a dataset, 'campaign_data.csv', containing detailed logs of user\n",
        "interactions. The dataset includes columns like 'UserID', 'AdID', 'InteractionTime', 'Clicks', 'Impressions', and 'UserRegion'.\n",
        "Before they can analyze the data, the team must clean and preprocess it due to inconsistencies and missing values.\n",
        "The 'Clicks' and 'Impressions' columns have some missing values, which should be set to 0, assuming no interaction occurred.\n",
        "Additionally, 'UserRegion' has some entries labeled as 'Unknown', which should be replaced with 'Not Specified' for clarity.\n",
        "The team then wants to aggregate the data to understand the performance of each ad.\n",
        "They decide to calculate the total number of clicks and impressions, as well as the click-through rate (CTR) for each 'AdID'.\n",
        "The CTR is defined as the total clicks divided by total impressions for each ad.\n",
        "They also want to rename 'AdID' to 'AdvertisementID' for consistency with their other reporting tools.\n",
        "How can the digital marketing team preprocess this dataset by handling time zone standardization, imputing missing values, renaming columns, and performing\n",
        "aggregation with group-by to analyze the performance of each ad in their campaign?"
      ],
      "metadata": {
        "id": "Y-J5XBjd1cEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:30**\n",
        "Use **stock_prices.csv** and **stock_info.csv** files provided to you.\n",
        "A financial analytics firm is preparing to analyze stock data from two distinct datasets – 'stock_prices.csv' with daily stock prices and 'stock_info.csv' with stock\n",
        "information – and encounters various data irregularities, what comprehensive steps would be necessary for them to thoroughly cleanse and standardize\n",
        "their data for in-depth market trend analysis? The firm is faced with the tasks of imputing missing 'OpeningPrice' and 'ClosingPrice' values in 'stock_prices.csv',\n",
        "correcting potential outliers in 'MarketCap' values in 'stock_info.csv', standardizing inconsistent 'Sector' categorizations, and identifying and addressing any\n",
        "additional outliers in both datasets, particularly in key financial metrics that could significantly skew their analysis.\n",
        "Furthermore, they need to merge these datasets on 'StockID' for a unified view. How should the firm approach these preprocessing tasks,\n",
        "including the detection and handling of outliers, to ensure the data's integrity and usefulness for their analysis?"
      ],
      "metadata": {
        "id": "6vy7_iaV1cio"
      }
    }
  ]
}