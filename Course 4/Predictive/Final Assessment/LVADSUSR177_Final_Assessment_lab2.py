# -*- coding: utf-8 -*-
"""Lab2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SDEgren2JkgyOnLbhFfPGBUx8PTyVBX-

1.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/penguins_classification.csv')

df.head()

df.shape

df.isnull().sum()

df.dtypes

df.info()

"""2."""

df.describe()

"""3."""

#detecting outliers
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(16,7))
sns.boxplot(df)
plt.show()

df.duplicated().sum()

df['island'].value_counts()

df['species'].value_counts()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['island'] = le.fit_transform(df['island'])
df['species'] = le.fit_transform(df['species'])

#detecting outlier
import numpy as np
from scipy.stats import zscore
threshold = 3.0
z_scores = zscore(df)
outliers = np.abs(z_scores) > threshold
df = df[~outliers]

#detecting outliers
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(16,7))
sns.boxplot(df)
plt.show()

#handling outlier
from sklearn.impute import SimpleImputer
imp = SimpleImputer(strategy="mean")
df["body_mass_g"]=imp.fit_transform(df[["body_mass_g"]])

df.isnull().sum()

df["bill_length_mm"]=imp.fit_transform(df[["bill_length_mm"]])

plt.figure(figsize=(15,8))
sns.heatmap(df.corr(),cmap="viridis",annot=True)

sns.pairplot(df,y_vars="species")

df.head()

x=df.drop(columns="species")
y=df["species"]

# Splitting the dataset into training and test set.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)

#feature Scaling
from sklearn.preprocessing import StandardScaler
st_x= StandardScaler()
x_train= st_x.fit_transform(x_train)
x_test= st_x.transform(x_test)

"""4."""

import xgboost as xgb

# Initialize the XGBoost Classifier
xgb_classifier = xgb.XGBClassifier()

# Train the model on the training data
xgb_classifier.fit(x_train, y_train)

# Make predictions on the testing data
y_pred = xgb_classifier.predict(x_test)

# Evaluate the model
from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

#Predicting the test set result
y_pred= xgb_classifier.predict(x_test)

"""5."""

#Creating the metrics of the model
from sklearn.metrics import accuracy_score,confusion_matrix, classification_report
print("Accuracy Score: ",accuracy_score(y_test,y_pred))
cm= confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,5))
sns.heatmap(cm,annot=True,cmap="viridis")
plt.plot()
print("Classification Report: ")
print(classification_report(y_test,y_pred))
print("Confusion Matrix")

