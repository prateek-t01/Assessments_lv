Agenda,,,,,,,,,,,
1,Overview of Random Forest Classifier & Demo.,,,,,,,,,,
2,Ensemble Methods - Bagging & Boosting & Stacking,,,,,,,,,,
3,XGBoost,,,,,,,,,,
4,AdaBoost,,,,,,,,,,
5,SVMClassifier,,,,,,,,,,
,,,,,,,,,,,
6,Unsupervised Algorithm Intro,,,,,,,,,,
7,KMeans Clustering,,,,,,,,,,
8,How clustering can be used in regression problem,,,,,,,,,,
9,K Value Selection,,,,,,,,,,
,,,,,,,,,,,
,,,,,,,,,,,
,,"Issues with DT:
1.Overfitting
2.High Variance",,,,,,,,,
,,,We want to reduce the variance of the decision tree to make it more generalized model.,,,,,,,,
,,,,,,,,,,,
,,Random Forest,,,,,,,,,
,,,,,,,,,,,
,,1,Create Bootstrap samples with the dataset,,,train data -5 rows,,Out of Bag Data points,,,
,,1.1,samples are repeated,,,BS1,"rows - 1,2,3,3,2","4,5",,,
,,1.2,not all data points are included in each BS,,,BS2,"rows - 1,3,5,4,3",2,,,
,,1.3,each BS sample size is same as training data ,,,BS3,"rows - 2,3,4,4,5",1,,,
,,1.4,"In each node in the sub trees, will not use all the independent features for the split.",,,,,,,,
,,,,,,,,,,,
,,,,,,,,,,,
,,,Why Bootstrapping?,,,,,,,,
,,1,To make sure each DT created for BS sample different from one another,,,,,,,,
,,2,We have introduced bias in BS sample to make sure that DT created on them are weak,,,,,,,,
,,,,,,,,,,,
,,,,,,BS1,DT1,1,,,
,,,,,,BS2,DT2,1,,,
,,,,,,BS3,DT3,0,,,
,,,,,,Voting,,1,,,
,,,,,,Aggregation/Final Decision,,,,,
,,,,,,,,,,,
,,,,,,,,,,,
,,x1,x2,y_actual,y_pred,BS1/DT1,BS2/DT2,BS3/DT3,BS4/DT4,BS5/DT5,BS6/DT6
,1,,,1,1,x,0,x,1,1,x
,2,,,1,0,x,x,x,1,0,0
,3,,,0,0,x,0,0,x,0,x
,4,,,1,1,x,1,x,x,0,1
,5,,,0,0,0,x,x,x,0,0
,6,,,1,1,x,1,x,x,1,1
,7,,,0,1,1,1,x,0,x,x
,8,,,0,0,x,0,x,1,1,x
,9,,,0,0,x,0,x,1,1,x
,10,,,0,0,x,0,x,1,1,x
,,,,,,,,,,,
,,,,x - is the data point is part of that BS/DT ,,,,,,,
,,,,,,,,,,,
,,Random Forest Hyperparameters,,,,,,,,,
,,,,,,,,,,,
,,,,,,,,,,,
Boosting OR Additive Combining,,,,,,,,,,,
1,Unlike Bagging - It's sequential process,,,,,,,,,,
2,Sequentially improve the performance of the model by reducing error,,,,,,,,,,
,,,,,,,,,,,
,,,,,,,,,,,
,M1->M2->M3->M,,,,,error,,error,,error,
,,x1,x2,y_actual,y_pred1,y_actual-y_pred,y_pred2,y_actual-(y_pred1+y_pred2),y_pred3,y_actual-(y_pred1+y_pred2+y_pred3),
,,,,2,5,-3,-1,-2,-1.5,-0.5,
,,,,4,5,-1,-0.5,-0.5,-0.5,0,
,,,,6,5,1,0.5,0.5,0.3,0.2,
,,,,8,5,3,1,2,1.2,0.8,
,,,,,,,error - as your target,,,,
XGBDT,"From Base GBDT, then added row sampling & column sampling to bring XGBDT",,,,M1,,M2,,M3,,
,,,,,,,,,,,
,XGBT,,,,,,,,,,
,Parallel Feature Selection,,,,,,,,,,
,Parallel Tree to grow,,,,,,,,,,
,,,,,,,,,,,
LightBoost,,,,,,,,,,,
,Minimized Errors are not considered for next sequence,,,,,,,,,,
,,,,,,,,,,,
AdaBoost,More importance to the weak learners,,,,,,,,,,
,,,,,,,,,,,
,,,,,,,,,,,
SVM Classifier ,,,,,,,,,,,
,https://greitemann.dev/svm-demo,,,,,,,,,,
,,,,,,,,,,,
,,,,,,,,,,,
Stacking,M1 - Logistic,,,,,,,,,,
,M2 - DT,,,,,,,,,,
,M3 - Hyper param tuned DT,,,,,,,,,,
,M4,,,,,,,,,,
,,,,,,,,,,,
,M5 - Meta Classifier - DT,,,,,,,,,,